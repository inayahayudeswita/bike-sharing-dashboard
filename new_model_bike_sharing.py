# -*- coding: utf-8 -*-
"""new model bike sharing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X49Ke0PDIvtVF6_s4hFpCjtFSeb124V3
"""

# 1) Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
import warnings
warnings.filterwarnings('ignore')

sns.set(style="whitegrid")
plt.rcParams['figure.figsize'] = (8,5)

# 2) Load datasets
print("Loading datasets...")
day = pd.read_csv("/content/day.csv")
hour = pd.read_csv("/content/hour.csv")

print("day.csv shape:", day.shape)
print("hour.csv shape:", hour.shape)

# 3) Quick EDA
print('\n--- Dataset Info ---')
print(day.info())
print(hour.info())

print('\n--- Missing Values ---')
print('DAY:', day.isnull().sum().sum())
print('HOUR:', hour.isnull().sum().sum())

# 4) Data preprocessing function
def preprocess_data(df, dataset_name):
    """Preprocess data for modeling"""
    print(f"\nPreprocessing {dataset_name} dataset...")

    # Drop unnecessary columns
    cols_to_drop = ['casual', 'registered', 'cnt', 'dteday', 'instant']
    X = df.drop(columns=[col for col in cols_to_drop if col in df.columns])
    y = df['cnt']

    print(f"Features: {X.columns.tolist()}")
    print(f"X shape: {X.shape}, y shape: {y.shape}")

    return X, y

# 5) Train Random Forest model
def train_random_forest(X, y, dataset_name):
    """Train Random Forest model"""
    print(f"\nTraining {dataset_name} Random Forest...")

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Scale features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train Random Forest
    rf = RandomForestRegressor(
        n_estimators=100,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )

    rf.fit(X_train_scaled, y_train)

    # Predictions
    y_pred = rf.predict(X_test_scaled)

    # Calculate metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"‚úÖ {dataset_name} Performance:")
    print(f"R2 Score: {r2:.4f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"MAE: {mae:.2f}")

    return rf, scaler, X_test_scaled, y_test, y_pred

# 6) Feature importance
def plot_feature_importance(model, feature_names, dataset_name):
    """Plot feature importance"""
    importances = model.feature_importances_
    feature_imp_df = pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    }).sort_values('importance', ascending=False)

    print(f"\nüìä {dataset_name} - Top 5 Features:")
    print(feature_imp_df.head())

    plt.figure(figsize=(10, 6))
    feature_imp_df.head(10).plot.barh(x='feature', y='importance')
    plt.title(f'{dataset_name} - Feature Importance')
    plt.tight_layout()
    plt.show()

    return feature_imp_df

# 7) Plot results
def plot_predictions(y_test, y_pred, dataset_name):
    """Plot actual vs predicted values"""
    plt.figure(figsize=(12, 4))

    # Actual vs Predicted
    plt.subplot(1, 2, 1)
    plt.scatter(y_test, y_pred, alpha=0.5, s=20)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Actual')
    plt.ylabel('Predicted')
    plt.title(f'{dataset_name} - Actual vs Predicted')

    # Residuals
    plt.subplot(1, 2, 2)
    residuals = y_test - y_pred
    plt.scatter(y_pred, residuals, alpha=0.5, s=20)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('Predicted')
    plt.ylabel('Residuals')
    plt.title(f'{dataset_name} - Residual Plot')

    plt.tight_layout()
    plt.show()

# 8) Main training execution
print("üöÄ STARTING RANDOM FOREST TRAINING...")

# Train DAY model
print("\n" + "="*50)
print("üìÖ DAY DATASET TRAINING")
print("="*50)
X_day, y_day = preprocess_data(day, "DAY")
day_model, day_scaler, X_day_test, y_day_test, y_day_pred = train_random_forest(X_day, y_day, "DAY")
day_importance = plot_feature_importance(day_model, X_day.columns.tolist(), "DAY")
plot_predictions(y_day_test, y_day_pred, "DAY")

# Train HOUR model
print("\n" + "="*50)
print("‚è∞ HOUR DATASET TRAINING")
print("="*50)
X_hour, y_hour = preprocess_data(hour, "HOUR")
hour_model, hour_scaler, X_hour_test, y_hour_test, y_hour_pred = train_random_forest(X_hour, y_hour, "HOUR")
hour_importance = plot_feature_importance(hour_model, X_hour.columns.tolist(), "HOUR")
plot_predictions(y_hour_test, y_hour_pred, "HOUR")

# 9) Save models
print("\n" + "="*50)
print("üíæ SAVING MODELS...")
print("="*50)

# Save DAY model
joblib.dump(day_model, 'rf_day_model.pkl')
joblib.dump(day_scaler, 'day_scaler.pkl')
print("‚úÖ DAY model saved: rf_day_model.pkl")
print("‚úÖ DAY scaler saved: day_scaler.pkl")

# Save HOUR model
joblib.dump(hour_model, 'rf_hour_model.pkl')
joblib.dump(hour_scaler, 'hour_scaler.pkl')
print("‚úÖ HOUR model saved: rf_hour_model.pkl")
print("‚úÖ HOUR scaler saved: hour_scaler.pkl")

# 10) Performance comparison
print("\n" + "="*50)
print("üìà PERFORMANCE COMPARISON")
print("="*50)

day_r2 = r2_score(y_day_test, y_day_pred)
hour_r2 = r2_score(y_hour_test, y_hour_pred)

comparison_df = pd.DataFrame({
    'Dataset': ['DAY', 'HOUR'],
    'R2_Score': [day_r2, hour_r2],
    'RMSE': [
        np.sqrt(mean_squared_error(y_day_test, y_day_pred)),
        np.sqrt(mean_squared_error(y_hour_test, y_hour_pred))
    ],
    'MAE': [
        mean_absolute_error(y_day_test, y_day_pred),
        mean_absolute_error(y_hour_test, y_hour_pred)
    ],
    'Samples': [len(X_day), len(X_hour)]
})

print(comparison_df)

# Plot comparison
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
bars = plt.bar(comparison_df['Dataset'], comparison_df['R2_Score'],
               color=['#3498db', '#e74c3c'], alpha=0.8)
plt.title('R¬≤ Score Comparison')
plt.ylabel('R¬≤ Score')
for bar, value in zip(bars, comparison_df['R2_Score']):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
             f'{value:.3f}', ha='center', va='bottom')

plt.subplot(1, 3, 2)
bars = plt.bar(comparison_df['Dataset'], comparison_df['RMSE'],
               color=['#3498db', '#e74c3c'], alpha=0.8)
plt.title('RMSE Comparison')
plt.ylabel('RMSE')
for bar, value in zip(bars, comparison_df['RMSE']):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
             f'{value:.1f}', ha='center', va='bottom')

plt.subplot(1, 3, 3)
bars = plt.bar(comparison_df['Dataset'], comparison_df['Samples'],
               color=['#3498db', '#e74c3c'], alpha=0.8)
plt.title('Dataset Size')
plt.ylabel('Number of Samples')
for bar, value in zip(bars, comparison_df['Samples']):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
             f'{value:,}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# 11) Test loaded models
print("\n" + "="*50)
print("üß™ TESTING SAVED MODELS...")
print("="*50)

def test_loaded_models():
    """Test that saved models can be loaded and used"""
    try:
        # Load models
        day_model_loaded = joblib.load('rf_day_model.pkl')
        hour_model_loaded = joblib.load('rf_hour_model.pkl')
        day_scaler_loaded = joblib.load('day_scaler.pkl')
        hour_scaler_loaded = joblib.load('hour_scaler.pkl')

        print("‚úÖ All models loaded successfully!")

        # Test predictions
        day_sample = X_day.iloc[[0]]
        hour_sample = X_hour.iloc[[0]]

        day_pred = day_model_loaded.predict(day_scaler_loaded.transform(day_sample))
        hour_pred = hour_model_loaded.predict(hour_scaler_loaded.transform(hour_sample))

        print(f"üìÖ DAY sample - Actual: {y_day.iloc[0]}, Predicted: {day_pred[0]:.1f}")
        print(f"‚è∞ HOUR sample - Actual: {y_hour.iloc[0]}, Predicted: {hour_pred[0]:.1f}")

        return True

    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

test_loaded_models()

# 12) Usage example
print("\n" + "="*50)
print("üéØ HOW TO USE THE MODELS")
print("="*50)

print("""
# Load and use the models:
import joblib
import pandas as pd

# Load DAY model
day_model = joblib.load('rf_day_model.pkl')
day_scaler = joblib.load('day_scaler.pkl')

# Example new data for DAY prediction
new_day_data = pd.DataFrame({
    'season': [1], 'yr': [0], 'mnth': [1], 'holiday': [0],
    'weekday': [6], 'workingday': [0], 'weathersit': [2],
    'temp': [0.24], 'atemp': [0.29], 'hum': [0.81], 'windspeed': [0.0]
})

# Scale and predict
scaled_data = day_scaler.transform(new_day_data)
prediction = day_model.predict(scaled_data)
print(f"Predicted daily bikes: {prediction[0]:.0f}")

# For HOUR model, include 'hr' feature:
# new_hour_data should include 'hr' column
""")

print("\n" + "="*50)
print("üéâ TRAINING COMPLETE!")
print("="*50)
print("üìÅ Files created:")
print("   - rf_day_model.pkl (DAY Random Forest model)")
print("   - rf_hour_model.pkl (HOUR Random Forest model)")
print("   - day_scaler.pkl (DAY feature scaler)")
print("   - hour_scaler.pkl (HOUR feature scaler)")
print("\n‚úÖ Ready for predictions!")